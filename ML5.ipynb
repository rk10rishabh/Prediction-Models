{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c517df-7f8c-4072-93c2-6bd2b9aa8da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets:\n",
      "    support         itemsets\n",
      "0  0.533333          (Bread)\n",
      "1  0.566667         (Butter)\n",
      "2  0.600000           (Eggs)\n",
      "3  0.600000           (Milk)\n",
      "4  0.266667  (Butter, Bread)\n",
      "5  0.300000    (Eggs, Bread)\n",
      "6  0.300000    (Milk, Bread)\n",
      "7  0.266667   (Butter, Eggs)\n",
      "8  0.300000   (Butter, Milk)\n",
      "9  0.300000     (Eggs, Milk)\n",
      "\n",
      "Association Rules:\n",
      "   antecedents consequents   support  confidence      lift\n",
      "0     (Butter)     (Bread)  0.266667    0.470588  0.882353\n",
      "1      (Bread)    (Butter)  0.266667    0.500000  0.882353\n",
      "2       (Eggs)     (Bread)  0.300000    0.500000  0.937500\n",
      "3      (Bread)      (Eggs)  0.300000    0.562500  0.937500\n",
      "4       (Milk)     (Bread)  0.300000    0.500000  0.937500\n",
      "5      (Bread)      (Milk)  0.300000    0.562500  0.937500\n",
      "6     (Butter)      (Eggs)  0.266667    0.470588  0.784314\n",
      "7       (Eggs)    (Butter)  0.266667    0.444444  0.784314\n",
      "8     (Butter)      (Milk)  0.300000    0.529412  0.882353\n",
      "9       (Milk)    (Butter)  0.300000    0.500000  0.882353\n",
      "10      (Eggs)      (Milk)  0.300000    0.500000  0.833333\n",
      "11      (Milk)      (Eggs)  0.300000    0.500000  0.833333\n"
     ]
    }
   ],
   "source": [
    "#Assignment 17\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load dataset from CSV\n",
    "file_path = \"transactions.csv\"\n",
    "data = pd.read_csv(file_path, header=None).values.tolist()\n",
    "\n",
    "# Remove NaN values from transactions\n",
    "data = [[item for item in transaction if pd.notna(item)] for transaction in data]\n",
    "\n",
    "# Convert dataset to one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.2, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Extract association rules\n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=0.5)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06edfbe0-0949-42b7-a0c7-1a6411cd6f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets:\n",
      "    support          itemsets\n",
      "0  0.416667           (apple)\n",
      "1  0.375000          (banana)\n",
      "2  0.333333           (bread)\n",
      "3  0.250000          (butter)\n",
      "4  0.416667          (grapes)\n",
      "5  0.375000            (milk)\n",
      "6  0.458333          (orange)\n",
      "7  0.208333   (orange, apple)\n",
      "8  0.250000  (grapes, banana)\n",
      "\n",
      "Association Rules:\n",
      "  antecedents consequents   support  confidence      lift\n",
      "0    (orange)     (apple)  0.208333    0.454545  1.090909\n",
      "1     (apple)    (orange)  0.208333    0.500000  1.090909\n",
      "2    (grapes)    (banana)  0.250000    0.600000  1.600000\n",
      "3    (banana)    (grapes)  0.250000    0.666667  1.600000\n"
     ]
    }
   ],
   "source": [
    "#Assignment 18\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load new dataset from CSV\n",
    "file_path = \"market.csv\"\n",
    "data = pd.read_csv(file_path, header=None).values.tolist()\n",
    "\n",
    "# Exclude Transaction_ID (first column) and remove NaN values from transactions\n",
    "data = [[item for item in transaction[1:] if pd.notna(item)] for transaction in data]\n",
    "\n",
    "# Convert dataset to one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.2, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Extract association rules\n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=0.5)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff227eed-6687-4e00-b809-dc465880f811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets:\n",
      "   support           itemsets\n",
      "0      0.3       (headphones)\n",
      "1      0.5         (keyboard)\n",
      "2      0.3          (monitor)\n",
      "3      0.4            (mouse)\n",
      "4      0.2  (keyboard, mouse)\n",
      "\n",
      "Association Rules:\n",
      "  antecedents consequents  support  confidence  lift\n",
      "0  (keyboard)     (mouse)      0.2         0.4   1.0\n",
      "1     (mouse)  (keyboard)      0.2         0.5   1.0\n"
     ]
    }
   ],
   "source": [
    "#Assignment 19\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load new dataset from CSV\n",
    "file_path = \"product.csv\"\n",
    "data = pd.read_csv(file_path, header=None).values.tolist()\n",
    "\n",
    "# Exclude Transaction_ID (first column) and remove NaN values from transactions\n",
    "data = [[item for item in transaction[1:] if pd.notna(item)] for transaction in data]\n",
    "\n",
    "# Convert dataset to one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.2, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Extract association rules\n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=0.5)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c817577c-3e1b-492a-9eda-1dc9678cd893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets:\n",
      "   support            itemsets\n",
      "0     0.50           (mystery)\n",
      "1     0.50           (fiction)\n",
      "2     0.35           (romance)\n",
      "3     0.30         (self-help)\n",
      "4     0.30          (thriller)\n",
      "5     0.30         (biography)\n",
      "6     0.35  (mystery, fiction)\n",
      "7     0.20  (romance, fiction)\n",
      "\n",
      "Association Rules:\n",
      "  antecedents consequents  support  confidence      lift\n",
      "0   (mystery)   (fiction)     0.35    0.700000  1.400000\n",
      "1   (fiction)   (mystery)     0.35    0.700000  1.400000\n",
      "2   (romance)   (fiction)     0.20    0.571429  1.142857\n",
      "3   (fiction)   (romance)     0.20    0.400000  1.142857\n"
     ]
    }
   ],
   "source": [
    "#Assignment 20\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load new dataset from CSV\n",
    "file_path = \"movie.csv\"\n",
    "data = pd.read_csv(file_path, header=None).values.tolist()\n",
    "\n",
    "# Remove NaN values from transactions\n",
    "data = [[item for item in transaction if pd.notna(item)] for transaction in data]\n",
    "\n",
    "# Convert dataset to one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply FP-Growth algorithm\n",
    "frequent_itemsets = fpgrowth(df_encoded, min_support=0.2, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Extract association rules\n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=0.5)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59053605-44ab-461e-89b0-30fdcc9b8f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in e:\\setups\\anaconda\\lib\\site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in e:\\setups\\anaconda\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in e:\\setups\\anaconda\\lib\\site-packages (from mlxtend) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in e:\\setups\\anaconda\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in e:\\setups\\anaconda\\lib\\site-packages (from mlxtend) (3.8.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in e:\\setups\\anaconda\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\setups\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\setups\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\setups\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\setups\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\setups\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in e:\\setups\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\setups\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\setups\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\setups\\anaconda\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\setups\\anaconda\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\setups\\anaconda\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\setups\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.4 MB 656.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.4 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.7/1.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.4 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.1/1.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
